{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "session00introduction-homework-solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCnX8egcrOJll0NYuHcOH2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/compling2021/blob/main/session00introduction_homework_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A04lacMKrNJe"
      },
      "source": [
        "# Downloading / uploading a text corpus\n",
        "\n",
        "## Homework task: creating frequency dictionary of multiword expressions\n",
        "\n",
        "Further sections have been modified to create a dictionary of MWEs (N-word long)\n",
        "\n",
        "## George Orwell, 1984 novel: \n",
        "https://heibox.uni-heidelberg.de/d/d65daff8341e467c82b1/\n",
        "\n",
        "(texts in en, de, fr, es, it. You can search for a freely-available text in your own language).\n",
        "\n",
        "## Wikipedia corpus\n",
        "This site contains plain text versions of the Wikipedia:\n",
        "https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2735#\n",
        "\n",
        "You can download the version for your favourite language(s).\n",
        "\n",
        "1. Download the \"1984\" novel into your local drive\n",
        "2. Upload it onto the Colab file system:\n",
        "- *Files* button to the left \n",
        "- *Upload to Session storage* button\n",
        "3. Examine the file on Colab\n",
        "4. Write a command to download it onto your system automatically: tip -- google \"wget\" and use it in Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXKKCk4ow8fQ"
      },
      "source": [
        "# example for downloading files for different languages, e.g., German file in  from the https://heibox.uni-heidelberg.de/f/ea06aa47fe2d49959a62/\n",
        "# remove / insert comments to choose the language you want to work with\n",
        "\n",
        "# German\n",
        "# !wget https://heibox.uni-heidelberg.de/f/ea06aa47fe2d49959a62/?dl=1\n",
        "\n",
        "# Armenian\n",
        "# !wget https://heibox.uni-heidelberg.de/f/3255f672ff7b4190828a/?dl=1\n",
        "\n",
        "# Georgian\n",
        "# !wget https://heibox.uni-heidelberg.de/f/318b32556cdc44d38238/?dl=1\n",
        "\n",
        "# French\n",
        "# !wget https://heibox.uni-heidelberg.de/f/b0cc03fbdb6248cab544/?dl=1\n",
        "\n",
        "# Spanish\n",
        "# !wget https://heibox.uni-heidelberg.de/f/585ee5e9eb3548219c34/?dl=1\n",
        "\n",
        "# Italian\n",
        "# !wget https://heibox.uni-heidelberg.de/f/fe1ae20b08b240f3a4f0/?dl=1\n",
        "\n",
        "# English\n",
        "# !wget https://heibox.uni-heidelberg.de/f/00ee04d9b9544c298be7/?dl=1\n",
        "\n",
        "# Georgian 'Brown corpus'\n",
        "# !wget https://heibox.uni-heidelberg.de/f/d5603814da69440aadf4/?dl=1\n",
        "\n",
        "# English Brown corpus (text)\n",
        "!wget https://heibox.uni-heidelberg.de/f/d2c3543b757d49839ac8/?dl=1\n",
        "\n",
        "\n",
        "# renaming file\n",
        "!mv index.html?dl=1 go1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvrk6kE614_F"
      },
      "source": [
        "Now let's make a frequency dictionary from our file!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yxPWqXa255z"
      },
      "source": [
        "# step 1: importing standard Python libraries\n",
        "import sys, re, os\n",
        "import scipy.stats as ss\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfoF_uI-2_cC"
      },
      "source": [
        "# step 2: open your file for reading (change the name of the file for a different language / corpus)\n",
        "# FileInput = open(\"go1984en.txt\",'r')\n",
        "FileInput = open(\"go1984.txt\",'r')\n",
        "# open another file for writing (our output file)\n",
        "FileOutput = open(\"go1984-MWE-frq.txt\", 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgrQq9P3tXw"
      },
      "source": [
        "# step 3: create an empty frequency dictionary: words will be 'keys', frequencies will be 'values'\n",
        "DictionaryFrq = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0p9QF4x39p-"
      },
      "source": [
        "# step 4: read each line, clean it up, split it into words and count unique words:\n",
        "INGram = 2\n",
        "for Line in FileInput:\n",
        "    Line = re.sub('<.*?>', '', Line) # remove html/xml tags\n",
        "    Line = Line.lower() # convert to lower case\n",
        "    Line = Line.strip() # remove leading and final white spaces\n",
        "    ListOfWords = re.split('[ ,\\.:;\\!\\(\\)\\\"\\[\\]«»\\-\\?]+', Line) # tokenize: split on white spaces and punctuation\n",
        "    # remove empty words: https://stackoverflow.com/questions/3845423/remove-empty-strings-from-a-list-of-strings\n",
        "    ListOfWords = list(filter(None, ListOfWords))   \n",
        "    # sys.stdout.write( str( ListOfWords ) + '\\n' )\n",
        "\n",
        "    # If word exists, add 1 to its existing frequency; if it doesn't, then set frequency to 1\n",
        "    # { word1 : 4 , word2 : 4, word3 : 2 }\n",
        "    # -- homework -- how to do MWEs\n",
        "    # we use list slices: \n",
        "    # a[start:stop]\n",
        "    # \n",
        "    # for Word in ListOfWords:\n",
        "    for i in range(len(ListOfWords)):\n",
        "        # Word = ListOfWords[i]\n",
        "        if i+i+INGram > len(ListOfWords): break\n",
        "        try: LWordsMWE = ListOfWords[i:i+INGram]\n",
        "        except: LWordsMWE = []\n",
        "      \n",
        "        if LWordsMWE:\n",
        "            SWordsMWE = ' '.join(LWordsMWE)\n",
        "            try:\n",
        "                DictionaryFrq[SWordsMWE] += 1\n",
        "            except:\n",
        "                DictionaryFrq[SWordsMWE] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuoVg7eB4y8I"
      },
      "source": [
        "# step 5: save the frequency dictionary into file, by decreasing frequencies\n",
        "# FileOutput.write( str( DictionaryFrq ) + '\\n' )\n",
        "for Word, Frq in sorted( DictionaryFrq.items() , key=lambda x: x[1], reverse=True) :\n",
        "    FileOutput.write(Word + '\\t' + str(Frq) + '\\n')\n",
        "FileOutput.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYKESFuT5L9L"
      },
      "source": [
        "## Tasks\n",
        "1. Examine the frequencies file; \n",
        "2. download it onto your local machine; \n",
        "3. Change the programme to create a frequency dictionary from another file / corpus / language\n",
        "4. Change the programme to preserve lower/upper-case letters; how would you print out only words with frequency >1 ?\n",
        "5. Run it again and compare the results (save the results in another file).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeamIEr15Lev"
      },
      "source": [
        "LRanks = []\n",
        "LFrqs = []\n",
        "LCoef = []\n",
        "rank = 0\n",
        "for Word, Frq in sorted(DictionaryFrq.items() , key=lambda x: x[1], reverse=True):\n",
        "    rank +=1\n",
        "    coef = rank * Frq\n",
        "    LRanks.append(rank)\n",
        "    LFrqs.append(Frq)\n",
        "    LCoef.append(coef)\n",
        "\n",
        "print(len(LRanks))\n",
        "print(len(LFrqs))\n",
        "print(len(LCoef))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrtSuYu2EDzB"
      },
      "source": [
        "Let's plot rank vs. frequency\n",
        "(cf. our coefficient), scaled by log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJS1iWuy3VB0"
      },
      "source": [
        "plt.plot([math.log(c) for c in LRanks], [math.log(c) for c in LFrqs], 'ro')\n",
        "plt.plot([math.log(c) for c in LRanks], [math.log(c) for c in LCoef], 'bs')\n",
        "# plt.plot([c for c in LRanks], [c for c in LFrqs], 'bs')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}